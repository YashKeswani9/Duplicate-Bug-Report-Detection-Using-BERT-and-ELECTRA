{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1p8OJ57gmvg"
   },
   "source": [
    "# Setup and Preparation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oJz1K95L3nW7",
    "outputId": "4d3424d4-8f41-4a85-e903-8926c4b0cc9c"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CbbHPl2GFgv0",
    "outputId": "129ba032-01e4-43e5-cc53-1233f3beba27"
   },
   "outputs": [],
   "source": [
    "# %cd drive/MyDrive/data_nlp_proj\n",
    "%cd drive/MyDrive/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mCqpI8Vkcsys",
    "outputId": "5bac7eb4-2da6-4b8e-cdfd-fe8fb1f9f206"
   },
   "outputs": [],
   "source": [
    "%pip install datasets\n",
    "%pip install evaluate\n",
    "%pip install transformers[torch]\n",
    "%pip install -U accelerate\n",
    "! pip install optuna\n",
    "! pip install ray[tune]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMdrxZRBT64Z"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "295f00b7873c4e11b437741b6578a5ad",
      "a2b1d170b3874841a75efc3cd2a1c93a",
      "adbdab065cc14e41ac91bbf68ec0afde",
      "e911a0f89b6846d0b38b74bff572bc62",
      "01a27c6ab69046e9874ffa40ff2c3d7f",
      "a7417be740bc40ec8e98bee1b8c64503",
      "d4228195e4b94de79c9b51d79d96e377",
      "5e93e50868e5446fa3c43e66588c5a02",
      "b3a3f33d4784432ba0eb06cd201ab3bf",
      "cca93c023f534f388fc7ad45d151f47c",
      "e86596373df34b8a963316332e6f9960",
      "c2542ce359e14586be92244e47eea39b",
      "e6fe8a1ea068403b9d68d6aa8c7a37d9",
      "1be85e00208f4a41ad090fc3a72dbf21",
      "e62a126aa13f49f09ad57429268e2a9d",
      "78e83e4f91b44410961da92c660dc82e",
      "f102899e6000430589a66c8eb2220516",
      "4f82c5d72e0a4915a8a6a0bf63f527f5",
      "f343af8001c045829a4372db9ceaaeff",
      "d3d90e51a07040428ae994ad2d483bab",
      "c2e03e7d094b4ca4bb7a6288d4d1b833",
      "f223e913a0b94ea4af03c63e36701f6a",
      "c480e3478e0646479e3982fec11e9558",
      "cb9c2691bcdf4b1e890ba1aea38f46ef",
      "d28f9b1f3c8e4bffab04b6d2537f30cc",
      "fc89c66dcbf94483a509fa9714104155",
      "bd245a00d9e64c6dbe7db8bb17349288",
      "c001b3c3f91d4a929941fec0ecf92ace",
      "a3ece6182b0548749449d9a33ded44ae",
      "761f69ef11e0459a9498612509ce24c6",
      "be19dd9a37c842d09a312f538e6469f3",
      "9ed767bbebed490397f560aa5655afd3",
      "131ce0feadd14552bc4c151b7b22ca2b",
      "5004ab21cb0f462f8350fb86da551ea7",
      "868cebdbf0864fe2b52034ebc02225b8",
      "4cc56764d9234a25bb661271c4ac3fd1",
      "9ccfc092ed454cf7b8955f2ca3e40958",
      "f589c07bd0bf4906b27cd67799b54c74",
      "13da5f1c9f8e41da9c397c1e34e7cd3d",
      "e817f2cbd0d04a6e96ca0877da8e8e98",
      "ae282e0791d14dd088d9abfb4668f87a",
      "74f35c60ec234d249301170f433173be",
      "6a30ef56ea664fc78c2d7db89258a288",
      "c6fc1a675a3742e5a7fbf9545c28d1d7"
     ]
    },
    "id": "C-td2VhVXxZO",
    "outputId": "4ab28413-b7e2-45f6-dbd1-f63b31d681f7"
   },
   "outputs": [],
   "source": [
    "def load_data(train,test):\n",
    "  train_ds = datasets.load_dataset(\"csv\", data_files={\"train\": train, \"test\":test})\n",
    "  return train_ds\n",
    "train_ds = load_data('eclipse_train.csv', 'eclipse_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gnTqNFIGLp9T",
    "outputId": "ed4796c0-75c0-4a6d-9cb6-66770eb906a6"
   },
   "outputs": [],
   "source": [
    "print(train_ds['train'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209,
     "referenced_widgets": [
      "e1115eb622d2417e9c7b1ca2ffb1edea",
      "c1803b0db09c4f00977b0071dee09a70",
      "0a510442f6804b7a97649a7254e3d02e",
      "1bc241ef3011419aa648546d3ccc65f2",
      "9599cf9ced35408996716721417184c6",
      "fe68d14e7a584dfa97b15c4b898d974c",
      "8706735fa83646b4903afcaa2ab74cb6",
      "43888507dcf0460fbdd1aa8190674e55",
      "1825918d82444151928551e5c0e67c84",
      "577fdb849779400d8062e0a580e40490",
      "00566d2d981c47c3b4f6b2d5f9da25be",
      "ab039838e971470f9d21595650a32359",
      "1fc16da0797441499890c573d1b78634",
      "d9307dcdd6544d249e33d7cc27cf3129",
      "2891fd22da624ed781f3593cd4d0c865",
      "109e61e067e44933a2abbde85a40126a",
      "d4cf58eaee754683b5968c3c0d8e37ce",
      "c16137c45ad248e497bd67e9f1a4bdcf",
      "58757637b5a947e48434712e2718ca35",
      "a13ab1d3f034490f93f4b6fcfab0ec4b",
      "a0eee0e4305645b4b87edcb9073121ca",
      "c8ffc3319be2432881dd64191e2795e4",
      "a39817f951044534ad702cddd723181a",
      "7d83e3b846f6460286022ad209c0c3dc",
      "3845ea67fac84fb1a5d4c4098618bc2a",
      "b0fc0f90b94f4b63b13bc8e196dbb1ba",
      "7dcb9d7a2af84ceea589c070f18a6b2f",
      "f0cae217b82343a4a6d86aa03db41ab9",
      "2cbf0b446b8e4a8f9650c50c74e2e7f8",
      "e3302d199e4546b9b3e676646f60c66c",
      "af5b0132e21a475aaa2ac0d6fa276277",
      "2ed92bb1886c47168b886dccac37b8be",
      "83e8ae0d87e34a71800ef9cade0a7ad2",
      "d5d5a92b232c4457b2a71b38f033c184",
      "621e962b29204467b3b648e282ccddb0",
      "0ddfc4d1a3144b00a71f14e7d4de3677",
      "98c55e3770e743a7bb66b0161047b5be",
      "7883c88e767b48dfbea3410f417240be",
      "684202aa1af44b3daebc31dfe9236202",
      "c06247bd24e44ed7912ca71380012e98",
      "d1908eaae1b24b41885682e508863ba7",
      "f4ee2401ee154a53bf82b6afad0c001d",
      "c6269cfc0e5748949075dee3d5289caa",
      "8cc70ecc3f79431d8e29cce9f4844ccc",
      "ae53dfaf7e334611a078076a4b0d28dd",
      "7973cd6c3379490dabc081c09162c032",
      "7b55c67c05784e50ba3844c849b3b940",
      "f67f874501a34316920486e30fb66820",
      "a7c1774377ae42b389ebf78cd7364609",
      "02f0a264f80646a0956350da68e37621",
      "52f6911517a7486b97aa139683cfc9e6",
      "ab28939e337c47f8b70959b06979306e",
      "6527e9038315490cbe1b1d81d5352a8e",
      "6e48cb163269498bbeb17a783c139940",
      "71567ed949ae4e44ac66249b00a065d3",
      "a3cee6453a6649f8a030a8b77386eb38",
      "7a761b9003e6450f8e2ec3242972ae50",
      "6bf4ccd65de2447eb387a3bec3bd7a34",
      "2c61f4bf3d0f450fbe6da0bb88a91e87",
      "97dfd43d4091420c8eec5247c2212c09",
      "572b0ce2f1624b7d9c1e9c40eb6f9fb2",
      "58c7090541514afbb23c007f24383c1d",
      "1a33734716fe4e918724534f5a40573c",
      "0280d919bc8f42aaba2a14d6ccf4b8b9",
      "74c2e202f0cb43e38615221580c545a8",
      "bcbc9af68c6042db90685a07c5ee40a6"
     ]
    },
    "id": "reohNYK2egMr",
    "outputId": "3f76d587-e148-43f1-deb3-377bdc46dbd8"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the texts\n",
    "    return tokenizer(examples[\"text\"], padding=True, max_length=128, truncation=True,return_tensors=\"pt\")\n",
    "    # result['label'] = examples['Status']\n",
    "\n",
    "\n",
    "# c2l = ClassLabel(num_classes=2, names=['nondup', 'duplicate'])\n",
    "\n",
    "train = train_ds.map(\n",
    "preprocess_function,\n",
    "batched=True,\n",
    "desc=\"Running tokenizer on dataset\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IRiaKydibUW6",
    "outputId": "9a16b5ac-a6e7-4949-9a2b-4f055b191873"
   },
   "outputs": [],
   "source": [
    "print(train['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "nmqNBL18hq9O",
    "outputId": "56749c02-f1dd-4f92-e7fd-d5305349bfd6"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)\n",
    "training_args = TrainingArguments(output_dir='android', evaluation_strategy=\"epoch\")\n",
    "metric1 = evaluate.load(\"accuracy\")\n",
    "metric2 = evaluate.load(\"f1\")\n",
    "metric3 = evaluate.load(\"precision\")\n",
    "metric4 = evaluate.load(\"recall\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\n",
    "\n",
    "\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    precision = metric3.compute(predictions=predictions, references=labels)\n",
    "    recall = metric4.compute(predictions=predictions, references=labels)\n",
    "    f1 = metric2.compute(predictions=predictions, references=labels)\n",
    "    accuracy = metric1.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1, \"accuracy\": accuracy}\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "      model=model,\n",
    "      args=training_args,\n",
    "      train_dataset=train['train'],\n",
    "      eval_dataset=train['test'],\n",
    "      data_collator=data_collator,\n",
    "      compute_metrics=compute_metrics\n",
    "  )\n",
    "trainer.train() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsoqOPwIiF4d"
   },
   "source": [
    "# BERT (Default parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "6ziVsCmriNHg",
    "outputId": "b99dcb61-0957-4b06-dafb-49fc2199bdae"
   },
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQ28lDCEiNka"
   },
   "source": [
    "# BERT (Hyperparameter-Tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "u5pmXgfZiP54",
    "outputId": "9a09d80b-8452-451a-9924-549253a6608f"
   },
   "outputs": [],
   "source": [
    "# Added temporarily\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)\n",
    "\n",
    "# Added temporarily\n",
    "metric1 = evaluate.load(\"accuracy\")\n",
    "metric2 = evaluate.load(\"f1\")\n",
    "metric3 = evaluate.load(\"precision\")\n",
    "metric4 = evaluate.load(\"recall\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "def compute_metrics_tune(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric2.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# Added temporarily\n",
    "training_args = TrainingArguments(output_dir='android', evaluation_strategy=\"epoch\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=train[\"train\"].shard(index=1, num_shards=10) ,\n",
    "    eval_dataset=train[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics_tune\n",
    ")\n",
    "\n",
    "best_run = trainer.hyperparameter_search(n_trials=5, direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ND5TZq4IZ88Z",
    "outputId": "40d9805c-3fd8-4587-d031-46343568e900"
   },
   "outputs": [],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEyyqOoBiQNr"
   },
   "source": [
    "# ELECTRA (Fine-Tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Ua8zjE2iV9W"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the texts\n",
    "    return tokenizer(examples[\"text\"], padding=True, max_length=128, truncation=True,return_tensors=\"pt\")\n",
    "    # result['label'] = examples['Status']\n",
    "\n",
    "\n",
    "# c2l = ClassLabel(num_classes=2, names=['nondup', 'duplicate'])\n",
    "\n",
    "train = train_ds.map(\n",
    "preprocess_function,\n",
    "batched=True,\n",
    "desc=\"Running tokenizer on dataset\",\n",
    ")\n",
    "\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the texts\n",
    "    return tokenizer(examples[\"text\"], padding=True, max_length=128, truncation=True,return_tensors=\"pt\")\n",
    "    # result['label'] = examples['Status']\n",
    "\n",
    "\n",
    "# c2l = ClassLabel(num_classes=2, names=['nondup', 'duplicate'])\n",
    "\n",
    "train = train_ds.map(\n",
    "preprocess_function,\n",
    "batched=True,\n",
    "desc=\"Running tokenizer on dataset\",\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"google/electra-base-discriminator\", num_labels=2)\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer/android\", evaluation_strategy=\"epoch\")\n",
    "metric1 = evaluate.load(\"accuracy\")\n",
    "metric2 = evaluate.load(\"f1\")\n",
    "metric3 = evaluate.load(\"precision\")\n",
    "metric4 = evaluate.load(\"recall\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\n",
    "\n",
    "\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    precision = metric3.compute(predictions=predictions, references=labels)\n",
    "    recall = metric4.compute(predictions=predictions, references=labels)\n",
    "    f1 = metric2.compute(predictions=predictions, references=labels)\n",
    "    accuracy = metric1.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1, \"accuracy\": accuracy}\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "      model=model,\n",
    "      args=training_args,\n",
    "      train_dataset=train['train'],\n",
    "      eval_dataset=train['test'],\n",
    "      data_collator=data_collator,\n",
    "      compute_metrics=compute_metrics\n",
    "  )\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "l7kWfhi-T__L",
    "8EeasEMqMi9F"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
